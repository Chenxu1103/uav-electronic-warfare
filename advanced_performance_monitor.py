#!/usr/bin/env python3
"""
é«˜çº§æ€§èƒ½ç›‘æ§å™¨

å®æ—¶ç›‘æ§å’Œåˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®æŒ‡æ ‡ï¼š
1. å®æ—¶æ€§èƒ½æ›²çº¿ç»˜åˆ¶
2. æ€§èƒ½ç“¶é¢ˆè¯Šæ–­
3. è®­ç»ƒå»ºè®®ç”Ÿæˆ
4. å¤šç»´åº¦æŒ‡æ ‡åˆ†æ
5. è®ºæ–‡æŒ‡æ ‡è¾¾æˆé¢„æµ‹
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import json
import glob
from datetime import datetime
from typing import Dict, List, Tuple
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

class AdvancedPerformanceMonitor:
    """é«˜çº§æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.paper_targets = {
            'reconnaissance_completion': 0.97,
            'safe_zone_development_time': 2.1,
            'reconnaissance_cooperation_rate': 37.0,
            'jamming_cooperation_rate': 34.0,
            'jamming_failure_rate': 23.3
        }
        
        # æ€§èƒ½åŸºå‡†
        self.performance_benchmarks = {
            'excellent': 90,    # 90%+ è®ºæ–‡è¾¾æˆç‡
            'good': 75,         # 75%+ è®ºæ–‡è¾¾æˆç‡
            'acceptable': 60,   # 60%+ è®ºæ–‡è¾¾æˆç‡
            'poor': 60          # 60%ä»¥ä¸‹
        }
        
    def load_experiment_results(self, experiment_dir="experiments"):
        """åŠ è½½å®éªŒç»“æœ"""
        print("ğŸ“Š åŠ è½½å®éªŒç»“æœ...")
        
        results = []
        
        # æœç´¢æ‰€æœ‰å®éªŒç›®å½•
        search_patterns = [
            f"{experiment_dir}/*/final_reproduction_results.json",
            f"{experiment_dir}/*/ultra_advanced_results.json",
            f"{experiment_dir}/*/enhanced_reproduction_results.json"
        ]
        
        for pattern in search_patterns:
            files = glob.glob(pattern)
            for file_path in files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                    # æå–ç³»ç»Ÿä¿¡æ¯
                    system_type = data.get('system_type', 'unknown')
                    timestamp = data.get('timestamp', 'unknown')
                    achievement_rate = data.get('achievement_rate', 0)
                    final_metrics = data.get('final_metrics', {})
                    
                    results.append({
                        'system_type': system_type,
                        'timestamp': timestamp,
                        'achievement_rate': achievement_rate,
                        'metrics': final_metrics,
                        'file_path': file_path
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•åŠ è½½ {file_path}: {e}")
        
        print(f"âœ… å·²åŠ è½½ {len(results)} ä¸ªå®éªŒç»“æœ")
        return results
    
    def analyze_performance_trends(self, results):
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        print("\nğŸ“ˆ æ€§èƒ½è¶‹åŠ¿åˆ†æ")
        print("="*80)
        
        if not results:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å®éªŒç»“æœ")
            return
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_results = sorted(results, key=lambda x: x['timestamp'])
        
        # åˆ†æå„ç³»ç»Ÿç±»å‹çš„æ€§èƒ½
        system_performance = {}
        for result in sorted_results:
            system_type = result['system_type']
            if system_type not in system_performance:
                system_performance[system_type] = []
            system_performance[system_type].append(result)
        
        print("ğŸ¯ å„ç³»ç»Ÿæ€§èƒ½å¯¹æ¯”:")
        print("-" * 60)
        
        for system_type, results_list in system_performance.items():
            if results_list:
                latest_result = results_list[-1]
                avg_achievement = np.mean([r['achievement_rate'] for r in results_list])
                max_achievement = max([r['achievement_rate'] for r in results_list])
                
                print(f"{system_type}:")
                print(f"  å®éªŒæ¬¡æ•°: {len(results_list)}")
                print(f"  å¹³å‡è¾¾æˆç‡: {avg_achievement:.1f}%")
                print(f"  æœ€é«˜è¾¾æˆç‡: {max_achievement:.1f}%")
                print(f"  æœ€æ–°è¾¾æˆç‡: {latest_result['achievement_rate']:.1f}%")
                
                # æ€§èƒ½ç­‰çº§è¯„ä¼°
                if max_achievement >= self.performance_benchmarks['excellent']:
                    level = "ğŸ”¥ ä¼˜ç§€"
                elif max_achievement >= self.performance_benchmarks['good']:
                    level = "ğŸ‰ è‰¯å¥½"
                elif max_achievement >= self.performance_benchmarks['acceptable']:
                    level = "âœ… å¯æ¥å—"
                else:
                    level = "âš ï¸ éœ€è¦æ”¹è¿›"
                
                print(f"  æ€§èƒ½ç­‰çº§: {level}")
                print()
    
    def analyze_key_metrics_breakdown(self, results):
        """åˆ†æå…³é”®æŒ‡æ ‡ç»†åˆ†"""
        print("\nğŸ” å…³é”®æŒ‡æ ‡ç»†åˆ†åˆ†æ")
        print("="*80)
        
        if not results:
            return
        
        # æ‰¾åˆ°æœ€ä½³ç»“æœ
        best_result = max(results, key=lambda x: x['achievement_rate'])
        metrics = best_result['metrics']
        
        print(f"ğŸ“Š æœ€ä½³æ€§èƒ½ç³»ç»Ÿ: {best_result['system_type']}")
        print(f"ğŸ“… æ—¶é—´: {best_result['timestamp']}")
        print(f"ğŸ¯ æ€»ä½“è¾¾æˆç‡: {best_result['achievement_rate']:.1f}%")
        print()
        
        print("ğŸ“ˆ å„æŒ‡æ ‡è¯¦ç»†åˆ†æ:")
        print("-" * 100)
        print(f"{'æŒ‡æ ‡':<25} {'è®ºæ–‡ç›®æ ‡':<12} {'å®ç°å€¼':<12} {'æœ€é«˜å€¼':<12} {'è¾¾æˆç‡':<10} {'çŠ¶æ€':<10} {'åˆ†æ':<15}")
        print("-" * 100)
        
        target_mapping = {
            'reconnaissance_completion': ('ä¾¦å¯Ÿä»»åŠ¡å®Œæˆåº¦', 0.97),
            'safe_zone_development_time': ('å®‰å…¨åŒºåŸŸå¼€è¾Ÿæ—¶é—´', 2.1),
            'reconnaissance_cooperation_rate': ('ä¾¦å¯Ÿåä½œç‡(%)', 37.0),
            'jamming_cooperation_rate': ('å¹²æ‰°åä½œç‡(%)', 34.0),
            'jamming_failure_rate': ('å¹²æ‰°å¤±æ•ˆç‡(%)', 23.3),
        }
        
        for key, (name, target) in target_mapping.items():
            if key in metrics:
                value = metrics[key]
                max_value = metrics.get(f'{key}_max', value)
                
                if key == 'jamming_failure_rate':
                    achievement = max(0, 100 - abs(value - target) / target * 100)
                else:
                    achievement = min(100, value / target * 100)
                
                # çŠ¶æ€åˆ†æ
                if achievement >= 90:
                    status = "ğŸ”¥ å®Œç¾"
                    analysis = "å·²è¾¾åˆ°è®ºæ–‡æ°´å‡†"
                elif achievement >= 75:
                    status = "ğŸ‰ ä¼˜ç§€"
                    analysis = "æ¥è¿‘è®ºæ–‡æ°´å‡†"
                elif achievement >= 60:
                    status = "âœ… è‰¯å¥½"
                    analysis = "æœ‰å¾…æå‡"
                else:
                    status = "âš ï¸ ä¸è¶³"
                    analysis = "éœ€è¦é‡ç‚¹ä¼˜åŒ–"
                
                print(f"{name:<25} {target:<12.3f} {value:<12.3f} {max_value:<12.3f} {achievement:<10.1f} {status:<10} {analysis:<15}")
        
        print("-" * 100)
    
    def diagnose_performance_bottlenecks(self, results):
        """è¯Šæ–­æ€§èƒ½ç“¶é¢ˆ"""
        print("\nğŸ”§ æ€§èƒ½ç“¶é¢ˆè¯Šæ–­")
        print("="*80)
        
        if not results:
            return
        
        # æ‰¾åˆ°æœ€ä½³ç»“æœè¿›è¡Œåˆ†æ
        best_result = max(results, key=lambda x: x['achievement_rate'])
        metrics = best_result['metrics']
        
        bottlenecks = []
        
        # æ£€æŸ¥å„é¡¹æŒ‡æ ‡
        jamming_coop = metrics.get('jamming_cooperation_rate', 0)
        if jamming_coop < 10:
            bottlenecks.append({
                'type': 'å¹²æ‰°åä½œç‡',
                'severity': 'critical' if jamming_coop < 2 else 'high',
                'current': jamming_coop,
                'target': 34.0,
                'suggestions': [
                    'å¢åŠ åä½œè®­ç»ƒæ¨¡å—æƒé‡',
                    'å»¶é•¿åä½œä¸“è®­é˜¶æ®µæ—¶é—´',
                    'ä¼˜åŒ–å¹²æ‰°æœºåˆ¶è®¾è®¡',
                    'å¢åŠ è”åˆå¹²æ‰°å¥–åŠ±'
                ]
            })
        
        safe_zone_time = metrics.get('safe_zone_development_time', 0)
        if safe_zone_time < 1.0:
            bottlenecks.append({
                'type': 'å®‰å…¨åŒºåŸŸå¼€è¾Ÿæ—¶é—´',
                'severity': 'high' if safe_zone_time < 0.5 else 'medium',
                'current': safe_zone_time,
                'target': 2.1,
                'suggestions': [
                    'ä¼˜åŒ–ä»»åŠ¡å®Œæˆå¥–åŠ±æœºåˆ¶',
                    'å¢åŠ æŒç»­æ€§ä»»åŠ¡è®¾è®¡',
                    'æ”¹è¿›ç¯å¢ƒçŠ¶æ€æŒä¹…åŒ–',
                    'è°ƒæ•´æ—¶é—´æ­¥é•¿è®¾ç½®'
                ]
            })
        
        recon_coop = metrics.get('reconnaissance_cooperation_rate', 0)
        if recon_coop < 25:
            bottlenecks.append({
                'type': 'ä¾¦å¯Ÿåä½œç‡',
                'severity': 'medium',
                'current': recon_coop,
                'target': 37.0,
                'suggestions': [
                    'å¼ºåŒ–å¤šæ™ºèƒ½ä½“åè°ƒæœºåˆ¶',
                    'ä¼˜åŒ–ä¿¡æ¯å…±äº«å¥–åŠ±',
                    'æ”¹è¿›é›†ä½“å†³ç­–ç®—æ³•',
                    'å¢åŠ åä½œæˆåŠŸæ£€æµ‹'
                ]
            })
        
        # è¾“å‡ºç“¶é¢ˆåˆ†æ
        if bottlenecks:
            print("ğŸš¨ å‘ç°æ€§èƒ½ç“¶é¢ˆ:")
            for i, bottleneck in enumerate(bottlenecks, 1):
                severity_icon = "ğŸ”´" if bottleneck['severity'] == 'critical' else "ğŸŸ¡" if bottleneck['severity'] == 'high' else "ğŸŸ¢"
                
                print(f"\n{severity_icon} ç“¶é¢ˆ {i}: {bottleneck['type']}")
                print(f"   å½“å‰å€¼: {bottleneck['current']:.2f}")
                print(f"   ç›®æ ‡å€¼: {bottleneck['target']:.2f}")
                print(f"   ä¸¥é‡ç¨‹åº¦: {bottleneck['severity']}")
                print(f"   ä¼˜åŒ–å»ºè®®:")
                for suggestion in bottleneck['suggestions']:
                    print(f"     â€¢ {suggestion}")
        else:
            print("ğŸ‰ æœªå‘ç°æ˜¾è‘—æ€§èƒ½ç“¶é¢ˆï¼ç³»ç»Ÿæ•´ä½“è¡¨ç°è‰¯å¥½ï¼")
    
    def generate_optimization_roadmap(self, results):
        """ç”Ÿæˆä¼˜åŒ–è·¯çº¿å›¾"""
        print("\nğŸ—ºï¸ æ€§èƒ½ä¼˜åŒ–è·¯çº¿å›¾")
        print("="*80)
        
        if not results:
            return
        
        best_result = max(results, key=lambda x: x['achievement_rate'])
        current_achievement = best_result['achievement_rate']
        
        print(f"ğŸ¯ å½“å‰æ€»ä½“è¾¾æˆç‡: {current_achievement:.1f}%")
        print()
        
        # æ ¹æ®å½“å‰æ€§èƒ½æ°´å¹³æä¾›è·¯çº¿å›¾
        if current_achievement < 30:
            print("ğŸ“ å½“å‰é˜¶æ®µ: åˆçº§ä¼˜åŒ–")
            print("ğŸ¯ çŸ­æœŸç›®æ ‡: è¾¾åˆ°50%è¾¾æˆç‡")
            print("ğŸ“‹ ä¼˜åŒ–é‡ç‚¹:")
            print("  1. åŸºç¡€ç½‘ç»œæ¶æ„ä¼˜åŒ–")
            print("  2. å¥–åŠ±æœºåˆ¶è°ƒæ•´")
            print("  3. ç¯å¢ƒå‚æ•°é…ç½®")
            print("  4. åŸºç¡€è®­ç»ƒç¨³å®šæ€§")
            
        elif current_achievement < 60:
            print("ğŸ“ å½“å‰é˜¶æ®µ: ä¸­çº§ä¼˜åŒ–")
            print("ğŸ¯ çŸ­æœŸç›®æ ‡: è¾¾åˆ°75%è¾¾æˆç‡")
            print("ğŸ“‹ ä¼˜åŒ–é‡ç‚¹:")
            print("  1. åä½œæœºåˆ¶å¼ºåŒ–")
            print("  2. é«˜çº§ç½‘ç»œæ¶æ„")
            print("  3. è¯¾ç¨‹å­¦ä¹ ç­–ç•¥")
            print("  4. æ€§èƒ½ç›‘æ§ç³»ç»Ÿ")
            
        elif current_achievement < 80:
            print("ğŸ“ å½“å‰é˜¶æ®µ: é«˜çº§ä¼˜åŒ–")
            print("ğŸ¯ çŸ­æœŸç›®æ ‡: è¾¾åˆ°90%è¾¾æˆç‡")
            print("ğŸ“‹ ä¼˜åŒ–é‡ç‚¹:")
            print("  1. è¶…å‚æ•°ç²¾ç»†è°ƒä¼˜")
            print("  2. é«˜çº§åä½œç®—æ³•")
            print("  3. ä¸“ä¸šåŒ–è®­ç»ƒæ¨¡å—")
            print("  4. æ€§èƒ½ç“¶é¢ˆçªç ´")
            
        else:
            print("ğŸ“ å½“å‰é˜¶æ®µ: é¡¶çº§ä¼˜åŒ–")
            print("ğŸ¯ ç›®æ ‡: è¾¾åˆ°è®ºæ–‡å®Œç¾æ°´å‡†")
            print("ğŸ“‹ ä¼˜åŒ–é‡ç‚¹:")
            print("  1. æè‡´æ€§èƒ½è°ƒä¼˜")
            print("  2. ç¨³å®šæ€§ä¿è¯")
            print("  3. æ³›åŒ–èƒ½åŠ›æå‡")
            print("  4. è®ºæ–‡çº§åˆ«æ”¶æ•›")
        
        # æ¨èä¸‹ä¸€æ­¥è¡ŒåŠ¨
        print(f"\nğŸš€ æ¨èä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
        if current_achievement < 50:
            print("  ğŸ“ è¿è¡Œ: enhanced_paper_reproduction_test.py")
            print("  ğŸ¯ é‡ç‚¹: åŸºç¡€æ€§èƒ½ç¨³å®š")
        elif current_achievement < 75:
            print("  ğŸ“ è¿è¡Œ: ultra_advanced_reproduction_system.py")
            print("  ğŸ¯ é‡ç‚¹: åä½œèƒ½åŠ›çªç ´")
        else:
            print("  ğŸ“ è¿è¡Œ: final_complete_reproduction_system.py")
            print("  ğŸ¯ é‡ç‚¹: è®ºæ–‡çº§åˆ«æ”¶æ•›")
    
    def plot_performance_curves(self, results):
        """ç»˜åˆ¶æ€§èƒ½æ›²çº¿"""
        print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨...")
        
        if not results:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ç»˜åˆ¶")
            return
        
        # æŒ‰ç³»ç»Ÿç±»å‹åˆ†ç»„
        system_types = {}
        for result in results:
            system_type = result['system_type']
            if system_type not in system_types:
                system_types[system_type] = []
            system_types[system_type].append(result)
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('è®ºæ–‡å¤ç°ç³»ç»Ÿæ€§èƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ€»ä½“è¾¾æˆç‡å¯¹æ¯”
        ax1 = axes[0, 0]
        system_names = list(system_types.keys())
        avg_achievements = [np.mean([r['achievement_rate'] for r in system_types[name]]) for name in system_names]
        max_achievements = [max([r['achievement_rate'] for r in system_types[name]]) for name in system_names]
        
        x = np.arange(len(system_names))
        width = 0.35
        
        ax1.bar(x - width/2, avg_achievements, width, label='å¹³å‡è¾¾æˆç‡', alpha=0.8)
        ax1.bar(x + width/2, max_achievements, width, label='æœ€é«˜è¾¾æˆç‡', alpha=0.8)
        ax1.set_xlabel('ç³»ç»Ÿç±»å‹')
        ax1.set_ylabel('è¾¾æˆç‡ (%)')
        ax1.set_title('æ€»ä½“è¾¾æˆç‡å¯¹æ¯”')
        ax1.set_xticks(x)
        ax1.set_xticklabels(system_names, rotation=45)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å…³é”®æŒ‡æ ‡é›·è¾¾å›¾
        ax2 = axes[0, 1]
        best_result = max(results, key=lambda x: x['achievement_rate'])
        metrics = best_result['metrics']
        
        # é›·è¾¾å›¾æ•°æ®
        labels = ['ä¾¦å¯Ÿå®Œæˆåº¦', 'å®‰å…¨åŒºåŸŸæ—¶é—´', 'ä¾¦å¯Ÿåä½œç‡', 'å¹²æ‰°åä½œç‡']
        values = [
            min(100, metrics.get('reconnaissance_completion', 0) / 0.97 * 100),
            min(100, metrics.get('safe_zone_development_time', 0) / 2.1 * 100),
            min(100, metrics.get('reconnaissance_cooperation_rate', 0) / 37.0 * 100),
            min(100, metrics.get('jamming_cooperation_rate', 0) / 34.0 * 100)
        ]
        
        angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
        values += values[:1]  # é—­åˆé›·è¾¾å›¾
        angles += angles[:1]
        
        ax2.plot(angles, values, 'o-', linewidth=2, label='å½“å‰æ€§èƒ½')
        ax2.fill(angles, values, alpha=0.25)
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(labels)
        ax2.set_ylim(0, 100)
        ax2.set_title('å…³é”®æŒ‡æ ‡è¾¾æˆç‡')
        ax2.grid(True)
        
        # 3. æ€§èƒ½è¶‹åŠ¿
        ax3 = axes[1, 0]
        for system_type, results_list in system_types.items():
            if len(results_list) > 1:
                sorted_results = sorted(results_list, key=lambda x: x['timestamp'])
                achievements = [r['achievement_rate'] for r in sorted_results]
                ax3.plot(range(len(achievements)), achievements, 'o-', label=system_type, linewidth=2)
        
        ax3.set_xlabel('å®éªŒæ¬¡æ•°')
        ax3.set_ylabel('è¾¾æˆç‡ (%)')
        ax3.set_title('æ€§èƒ½è¶‹åŠ¿')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. æŒ‡æ ‡åˆ†å¸ƒ
        ax4 = axes[1, 1]
        metrics_data = []
        labels = []
        
        for key, name in [('reconnaissance_completion', 'ä¾¦å¯Ÿå®Œæˆåº¦'), 
                         ('jamming_cooperation_rate', 'å¹²æ‰°åä½œç‡'),
                         ('reconnaissance_cooperation_rate', 'ä¾¦å¯Ÿåä½œç‡')]:
            values = [r['metrics'].get(key, 0) for r in results if key in r['metrics']]
            if values:
                metrics_data.append(values)
                labels.append(name)
        
        if metrics_data:
            ax4.boxplot(metrics_data, labels=labels)
            ax4.set_title('æŒ‡æ ‡åˆ†å¸ƒ')
            ax4.tick_params(axis='x', rotation=45)
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = f"performance_analysis_{timestamp}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ€§èƒ½å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        # æ˜¾ç¤ºå›¾è¡¨
        plt.show()
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¯åŠ¨é«˜çº§æ€§èƒ½ç›‘æ§åˆ†æ")
        print("="*80)
        
        # åŠ è½½å®éªŒç»“æœ
        results = self.load_experiment_results()
        
        if not results:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å®éªŒç»“æœï¼Œè¯·å…ˆè¿è¡Œä¸€äº›å®éªŒ")
            print("ğŸ’¡ å»ºè®®è¿è¡Œ:")
            print("  python quick_fix_test.py")
            print("  python ultra_advanced_quick_test.py")
            return
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        self.analyze_performance_trends(results)
        self.analyze_key_metrics_breakdown(results)
        self.diagnose_performance_bottlenecks(results)
        self.generate_optimization_roadmap(results)
        
        # ç”Ÿæˆå¯è§†åŒ–
        try:
            self.plot_performance_curves(results)
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        
        print("\nâœ… æ€§èƒ½åˆ†æå®Œæˆ!")
        
        # æä¾›ä¸‹ä¸€æ­¥å»ºè®®
        best_result = max(results, key=lambda x: x['achievement_rate'])
        print(f"\nğŸ¯ åŸºäºå½“å‰æœ€ä½³æˆæœ ({best_result['achievement_rate']:.1f}%) çš„å»ºè®®:")
        
        if best_result['achievement_rate'] < 50:
            print("ğŸ“ ç«‹å³è¿è¡Œ: python enhanced_paper_reproduction_test.py")
        elif best_result['achievement_rate'] < 80:
            print("ğŸ“ ç«‹å³è¿è¡Œ: python ultra_advanced_quick_test.py")
        else:
            print("ğŸ“ ç«‹å³è¿è¡Œ: python ultra_advanced_reproduction_system.py")

def main():
    """ä¸»å‡½æ•°"""
    monitor = AdvancedPerformanceMonitor()
    monitor.run_complete_analysis()

if __name__ == "__main__":
    main() 